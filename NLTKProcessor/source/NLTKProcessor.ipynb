{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "from nltk.corpus import stopwords\n",
    "import nltk as nltk\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLTKProcessor:\n",
    "    def __init__(self, tagger_path = None ,stop_words = None, pattern = None, tokenizer = lambda x: x.split()):\n",
    "        if tagger_path != None:\n",
    "            self._load_tagger(tagger_path)\n",
    "        else:\n",
    "            self.tagger = PerceptronTagger()\n",
    "        self.stop_words = stop_words\n",
    "        self.pattern = pattern\n",
    "        self.tokenizer = tokenizer\n",
    "        self.parser = nltk.RegexpParser(self.pattern)\n",
    "        \n",
    "    def tagger_training(self, taglist, tagger = PerceptronTagger(load=False) ):\n",
    "        self.tagger = tagger\n",
    "        self.tagger.train(taglist)\n",
    "        \n",
    "    def process(self, sent):\n",
    "        sent = self.tokenizer(unidecode(sent.lower()))\n",
    "        sent = self.tagger.tag(sent)\n",
    "        returner = []\n",
    "        aux_sent = ''\n",
    "        cs = self.parser.parse(sent)\n",
    "        for i in cs:\n",
    "            if len(i) < 2 and i[0][1] == 'K':\n",
    "                returner.append(i[0][0])\n",
    "            elif len(i) > 2:\n",
    "                for j in i:\n",
    "                    aux_sent += j[0]+' '\n",
    "                returner.append(aux_sent)\n",
    "                aux_sent = ''\n",
    "            elif isinstance(i[0],tuple):\n",
    "                returner.append(i[0][0]+' '+i[1][0])\n",
    "        return returner\n",
    "    \n",
    "    def raw_process(self, sent):\n",
    "        sent = self.tokenizer(unidecode(sent.lower()))\n",
    "        sent = self.tagger.tag(sent)\n",
    "        return sent\n",
    "    \n",
    "    def _load_tagger(self, path=None):\n",
    "        self.tagger = joblib.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\92007848\\\\Documents\\\\AIProj\\\\AiTeste\\\\NLTKAlpha\\\\Resources\\\\Models\\\\BetaTaggerV01.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '''NP:  {<K><N>} \n",
    "                  {<K>+}'''\n",
    "processor = NLTKProcessor(path, stopwords.words('portuguese'), pattern, nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['para consulta']\n"
     ]
    }
   ],
   "source": [
    "sent = \"na disciplina de arquitetura de computadores eles disponibilizam um maior número de pdf para consulta, sendo assim mesmo com pouca experiência consigo localizar o conteúdo referido e assim ter alguma chance... não seria possível aumentar a quantidade de materiais em pdf e a semelhança entre eles... de qualquer forma eu lhes agradeço\"\n",
    "print(processor.process(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ola', 'K'), ('estou', 'V'), ('com', 'PREP'), ('muita', 'PROADJ'), ('dificuldade', 'N'), ('de', 'PREP'), ('fazer', 'V'), ('o', 'ART'), ('trabalho', 'N'), (',', ','), ('a', 'ART'), ('questao', 'N'), ('1', 'N|AP'), ('eu', 'PROPESS'), ('consegui', 'V'), ('fazer', 'V'), ('mas', 'KC'), ('travei', 'V'), ('na', 'NPROP'), ('2', 'N'), ('nao', 'ADV'), ('tenho', 'V'), ('a', 'ART'), ('minima', 'N'), ('ideia', 'N'), ('de', 'PREP'), ('como', 'KS'), ('fazer', 'V'), ('esse', 'PROADJ'), ('sistema', 'N'), ('de', 'PREP'), ('apostas', 'N'), ('...', '...')]\n"
     ]
    }
   ],
   "source": [
    "print(processor.raw_process(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

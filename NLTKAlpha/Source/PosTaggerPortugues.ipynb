{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk as nltk\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "from nltk.corpus import floresta\n",
    "#nltk.download('mac_morpho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jersei', 'N'), ('atinge', 'V'), ('média', 'N'), ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exploração dos dados. \n",
    "#Utilizar essas linhas para ver o dataset de treino utilizado\n",
    "nltk.corpus.mac_morpho.words()\n",
    "nltk.corpus.mac_morpho.tagged_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = nltk.corpus.mac_morpho.tagged_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##def simplify_tag(t):\n",
    "##    if \"+\" in t:\n",
    "##        return t[t.index(\"+\")+1:]\n",
    "##    else:\n",
    "##        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##twords = nltk.corpus.floresta.tagged_words()\n",
    "##twords = [(w.lower(),simplify_tag(t)) for (w,t) in twords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CorpusList = []\n",
    "for new in tagged:\n",
    "    if new[0] != '':\n",
    "        CorpusList.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "taglist = []\n",
    "taglist.append(CorpusList)\n",
    "##taglist.append(twords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carrega um modelo\n",
    "from sklearn.externals import joblib\n",
    "tagger = joblib.load('C:\\\\Users\\\\92007848\\\\Documents\\\\IA proj\\\\Resourses\\\\Models\\\\tagger_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treina um modelo\n",
    "tagger = PerceptronTagger(load=False) # don't load existing model\n",
    "tagger.train(taglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = tagger.tag(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'art'),\n",
       " ('União', 'n'),\n",
       " ('Europeia', 'adj'),\n",
       " ('multou', 'v-fin'),\n",
       " ('o', 'art'),\n",
       " ('Google', 'n'),\n",
       " ('nesta', 'adj'),\n",
       " ('quarta-feira', 'adj'),\n",
       " ('(', 'prop'),\n",
       " ('18', 'num'),\n",
       " (')', 'n'),\n",
       " ('em', 'prp'),\n",
       " ('4,34', 'num'),\n",
       " ('bilhões', 'n'),\n",
       " ('de', 'prp'),\n",
       " ('euros', 'n'),\n",
       " ('(', 'adj'),\n",
       " ('aproximadamente', 'adv'),\n",
       " ('R', 'adj'),\n",
       " ('$', 'n'),\n",
       " ('19', 'num'),\n",
       " ('bi', 'n'),\n",
       " (')', 'adj'),\n",
       " ('por', 'prp'),\n",
       " ('práticas', 'n'),\n",
       " ('anticompetitivas', 'adj'),\n",
       " ('ao', 'prp'),\n",
       " ('priorizar', 'v-inf'),\n",
       " ('seus', 'pron-det'),\n",
       " ('aplicativos', 'n'),\n",
       " ('em', 'prp'),\n",
       " ('smartphones', 'prop'),\n",
       " ('em', 'prp'),\n",
       " ('detrimento', 'n'),\n",
       " ('de', 'prp'),\n",
       " ('concorrentes', 'n'),\n",
       " ('.', '.'),\n",
       " ('As', 'v-fin'),\n",
       " ('informações', 'n'),\n",
       " ('são', 'v-fin'),\n",
       " ('da', 'adj'),\n",
       " ('rede', 'n'),\n",
       " ('de', 'prp'),\n",
       " ('notícias', 'n'),\n",
       " ('CNN', 'adj'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = preprocess('''A União Europeia multou o Google nesta quarta-feira (18) em 4,34 bilhões de euros \n",
    "(aproximadamente R$ 19 bi) por práticas anticompetitivas ao priorizar seus aplicativos em \n",
    "smartphones em detrimento de concorrentes. As informações são da rede de notícias CNN.''')\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salva um modelo\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(tagger, 'C:\\\\Users\\\\92007848\\\\Documents\\\\IA proj\\\\Resourses\\\\Models\\\\tagger_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'NP: {<ART><ADJ>*<N|NPROP><N|NPROP>*<ADJ>*}'\n",
    "##pattern = 'NP: {<art><adj>*<n><n>*<adj>*}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP A/art União/n Europeia/adj)\n",
      "  multou/v-fin\n",
      "  (NP o/art Google/n nesta/adj quarta-feira/adj)\n",
      "  (/prop\n",
      "  18/num\n",
      "  )/n\n",
      "  em/prp\n",
      "  4,34/num\n",
      "  bilhões/n\n",
      "  de/prp\n",
      "  euros/n\n",
      "  (/adj\n",
      "  aproximadamente/adv\n",
      "  R/adj\n",
      "  $/n\n",
      "  19/num\n",
      "  bi/n\n",
      "  )/adj\n",
      "  por/prp\n",
      "  práticas/n\n",
      "  anticompetitivas/adj\n",
      "  ao/prp\n",
      "  priorizar/v-inf\n",
      "  seus/pron-det\n",
      "  aplicativos/n\n",
      "  em/prp\n",
      "  smartphones/prop\n",
      "  em/prp\n",
      "  detrimento/n\n",
      "  de/prp\n",
      "  concorrentes/n\n",
      "  ./.\n",
      "  As/v-fin\n",
      "  informações/n\n",
      "  são/v-fin\n",
      "  da/adj\n",
      "  rede/n\n",
      "  de/prp\n",
      "  notícias/n\n",
      "  CNN/adj\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "cp = nltk.RegexpParser(pattern)\n",
    "cs = cp.parse(sent)\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from pprint import pprint\n",
    "iob_tagged = tree2conlltags(cs)\n",
    "pprint(iob_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "namedEnt = nltk.ne_chunk(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namedEnt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
